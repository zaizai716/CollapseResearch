# Model Collapse Research Codebase

## Overview
This repository contains the implementation for **"The Curse of Recursion: Training on Generated Data Makes Models Forget"** (arXiv:2305.17493). The research demonstrates how training machine learning models recursively on AI-generated data leads to progressive degradation and eventual collapse of model quality.

## Core Concept
**Model Collapse**: When AI models are trained on data generated by previous generations of models rather than original human-created data, they progressively lose information about the true data distribution, particularly in the tails. This leads to:
- Reduced diversity in outputs
- Loss of rare events/edge cases  
- Convergence to narrow, simplified distributions
- Degraded model performance over generations

## Repository Structure

```
Nature_Model_Collapse/
├── Zakahler-curse_recurse-b48c90a/
│   ├── main.py                      # Main training script for language model experiments
│   ├── plt_model.py                  # PyTorch Lightning wrapper for model training
│   ├── dataset.py                    # WikiText2 dataset loading and preprocessing
│   ├── run_gmm_experiments.py        # Gaussian Mixture Model collapse experiments
│   ├── runme_base.py                 # Runner script for batch experiments
│   ├── VAE_experiments.ipynb         # Visual degradation experiments with VAEs
│   ├── Normals_GMM_experiments.ipynb # Additional GMM analysis notebook
│   └── experiment_results_summary.md # Detailed results documentation
```

## Key Components

### 1. Language Model Experiments (`main.py`)
- **Model**: Uses OPT-125M or GPT-2 for text generation
- **Dataset**: WikiText2 for language modeling
- **Process**: 
  1. Train model on original text data
  2. Generate synthetic text from trained model
  3. Train new model on generated text
  4. Repeat recursively to observe perplexity degradation
- **Metrics**: Perplexity increase indicates model quality loss

### 2. GMM Experiments (`run_gmm_experiments.py`)
- **Purpose**: Simplest mathematical demonstration of model collapse
- **Process**: Fit Gaussian Mixture Models recursively on synthetic data
- **Key Findings**:
  - Variance reduces by significant percentage per generation
  - Distribution modes converge toward center
  - L2 distance from original distribution increases exponentially

### 3. PyTorch Lightning Wrapper (`plt_model.py`)
- Handles training loop, validation, and testing
- Calculates perplexity for language model evaluation
- Supports checkpoint saving/loading for recursive training

### 4. Dataset Management (`dataset.py`)
- WikiText2 dataset downloading and caching
- Text tokenization and chunking (64 tokens default)
- Support for both original and generated datasets

## Key Parameters

### Training Arguments
- `--model_tag`: HuggingFace model to use (default: facebook/opt-125m)
- `--batch-size`: Training batch size (default: 128)
- `--learning-rate`: Initial LR (default: 2e-5)
- `--max-epochs`: Training epochs (default: 5)
- `--generate_percentage`: Mix ratio of generated vs original data

### Generation Control
- `--generate`: Save generated dataset to file
- `--load-generate`: Load previously generated dataset
- `--eval_only`: Skip training, only evaluate
- `--saveperplexities`: Save individual perplexity scores

## Experimental Workflow

### Basic Recursive Training
1. Train initial model on real data
2. Generate synthetic dataset using trained model
3. Train new model on synthetic data
4. Measure degradation (perplexity/variance)
5. Repeat for multiple generations

### Key Metrics to Monitor
- **Perplexity**: Higher = worse language understanding
- **Variance**: Lower = less diversity in outputs
- **L2 Distance**: Higher = further from original distribution

## Dependencies
- PyTorch & PyTorch Lightning
- Transformers (HuggingFace)
- NumPy, Matplotlib, scikit-learn
- CUDA-capable GPU recommended

## Important Findings
1. **Information Loss**: Each generation loses ~25-50% of distribution variance
2. **Tail Disappearance**: Rare events vanish within 3-5 generations
3. **Mode Collapse**: Multiple distribution modes merge into single mode
4. **Irreversible**: Once information is lost, it cannot be recovered

## Usage Example

```bash
# Train original model
python main.py -p --model_tag facebook/opt-125m --save-name gen0/

# Generate synthetic data
python main.py --load-name gen0/best.ckpt --generate gen1_data

# Train on synthetic data  
python main.py --load-generate gen1_data.pkl --save-name gen1/

# Evaluate degradation
python main.py --load-name gen1/best.ckpt --eval_only
```

## Research Impact
This work highlights critical risks in the age of synthetic data:
- Training on AI-generated content degrades model quality
- Internet pollution with AI content threatens future model training
- Need for careful data curation and human-generated content preservation
- Fundamental mathematical limits to recursive self-improvement

## Citation
Shumailov et al., "The Curse of Recursion: Training on Generated Data Makes Models Forget", arXiv:2305.17493, 2023